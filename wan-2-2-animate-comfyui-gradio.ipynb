{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13666598,"sourceType":"datasetVersion","datasetId":8689334},{"sourceId":13708953,"sourceType":"datasetVersion","datasetId":8721020},{"sourceId":13726076,"sourceType":"datasetVersion","datasetId":8732821},{"sourceId":13726184,"sourceType":"datasetVersion","datasetId":8732885},{"sourceId":13726280,"sourceType":"datasetVersion","datasetId":8732945},{"sourceId":13726587,"sourceType":"datasetVersion","datasetId":8733161},{"sourceId":13727491,"sourceType":"datasetVersion","datasetId":8733722},{"sourceId":13728542,"sourceType":"datasetVersion","datasetId":8734451},{"sourceId":13728642,"sourceType":"datasetVersion","datasetId":8734522},{"sourceId":13728722,"sourceType":"datasetVersion","datasetId":8734578},{"sourceId":13742285,"sourceType":"datasetVersion","datasetId":8743983},{"sourceId":13743579,"sourceType":"datasetVersion","datasetId":8744930},{"sourceId":13765803,"sourceType":"datasetVersion","datasetId":8760693},{"sourceId":13768043,"sourceType":"datasetVersion","datasetId":8762389}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport shutil\nimport warnings\nimport time\n\n# Suppress future warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# Create constraints file\n!echo \"numpy<2.0\" > /kaggle/working/constraints.txt\n\n# Set environment variable for the entire notebook\nimport os\nos.environ['PIP_CONSTRAINT'] = '/kaggle/working/constraints.txt'\n\n# --------------------------\n# 0. æ¸…ç†æ—§è¿›ç¨‹\n# --------------------------\nprint(\"æ¸…ç†æ—§è¿›ç¨‹...\")\n!pkill -f 'python main.py' || true\n!pkill -f 'pinggy' || true\n\n# --------------------------\n# 0.5 æ£€æµ‹å’Œé…ç½®å¤šGPU\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"æ£€æµ‹ GPU é…ç½®...\")\nprint(\"=\"*60)\n\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    print(f\"âœ“ æ£€æµ‹åˆ° {num_gpus} ä¸ª GPU\")\n    \n    for i in range(num_gpus):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        props = torch.cuda.get_device_properties(i)\n        print(f\"    - æ˜¾å­˜: {props.total_memory / 1024**3:.2f} GB\")\n    \n    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥å¯ç”¨å¤šGPU\n    if num_gpus > 1:\n        print(f\"\\nâœ“ é…ç½®å¤šGPUæ¨¡å¼ ({num_gpus} GPUs)\")\n        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, range(num_gpus)))\n    else:\n        print(\"\\nâš  ä»…æ£€æµ‹åˆ°1ä¸ªGPU\")\n        \nexcept Exception as e:\n    print(f\"âœ— GPUæ£€æµ‹å¤±è´¥: {e}\")\n\nprint(\"=\"*60)\n\n# --------------------------\n# 1. ç³»ç»Ÿä¾èµ–\n# --------------------------\nprint(\"å®‰è£…ç³»ç»Ÿåº“...\")\n!apt-get update -qq\n!apt-get install -y -qq libgl1 libglib2.0-0 ffmpeg\n\n# --------------------------\n# 2. å…‹éš† ComfyUI\n# --------------------------\nprint(\"å…‹éš† ComfyUI ä»“åº“...\")\nif not os.path.exists(\"ComfyUI\"):\n    !git clone https://github.com/comfyanonymous/ComfyUI.git\n\n%cd ComfyUI\nprint(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\nprint(\"æ›´æ–° ComfyUI...\")\n!git pull\n\n# --------------------------\n# 3. å®‰è£… Python åº“ (ä¼˜åŒ–ç‰ˆæœ¬ç»„åˆ)\n# --------------------------\nprint(\"å®‰è£…é¢å¤–ä¾èµ–...\")\n!pip install -q mediapipe\n!pip uninstall onnxruntime -y\n!pip install onnxruntime-gpu\n\nimport onnxruntime as ort\nprint(ort.get_available_providers())\n# Should show: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n\n# SAM-2 needs to be installed from git\n!pip install -q git+https://github.com/facebookresearch/segment-anything-2.git\n\nprint(\"å¸è½½ä¸å…¼å®¹åº“...\")\n!pip uninstall -y torch torchvision torchaudio xformers\n\nprint(\"å®‰è£…æœ€æ–° PyTorch nightly (WanVideoWrapper è¦æ±‚ 2.7.0.dev20250226+)...\")\n!pip install --pre --upgrade --extra-index-url https://download.pytorch.org/whl/nightly/cu121 torch torchvision torchaudio\n\nprint(\"å®‰è£…å…¼å®¹çš„ xformers...\")\n!pip install -q xformers\n\nprint(\"å®‰è£… ComfyUI å…¶ä½™ä¾èµ–...\")\n\n# Downgrade numpy to avoid incompatibility with custom nodes\n\n!pip install -q -r requirements.txt --no-deps\n!pip install -q torchsde einops transformers safetensors aiohttp accelerate pyyaml opencv-python pillow scipy imageio[ffmpeg] moviepy huggingface_hub gguf\n!pip install -q pydantic-settings python-dotenv\n\n# --------------------------\n# 4. éªŒè¯å®‰è£…\n# --------------------------\nprint(\"\\n\" + \"=\"*50)\nprint(\"éªŒè¯ PyTorch å’Œ xformers...\")\nprint(\"=\"*50)\ntry:\n    import torch\n    import torchvision\n    import xformers\n    import xformers.ops\n    \n    print(f\"âœ“ PyTorch: {torch.__version__}\")\n    print(f\"âœ“ TorchVision: {torchvision.__version__}\")\n    print(f\"âœ“ xformers: {xformers.__version__}\")\n    print(f\"âœ“ CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n    \n    if torch.cuda.is_available():\n        num_gpus = torch.cuda.device_count()\n        print(f\"âœ“ GPU æ•°é‡: {num_gpus}\")\n        for i in range(num_gpus):\n            print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n        print(f\"âœ“ CUDA ç‰ˆæœ¬: {torch.version.cuda}\")\n    \n    # éªŒè¯ RMSNorm å¯ç”¨æ€§\n    if hasattr(torch.nn, 'RMSNorm'):\n        print(\"âœ“ RMSNorm å¯ç”¨ (WanVideoWrapper å°†æ­£å¸¸å·¥ä½œ)\")\n    else:\n        print(\"âœ— RMSNorm ä¸å¯ç”¨\")\n        \n    print(\"=\"*50)\nexcept Exception as e:\n    print(f\"âœ— éªŒè¯å¤±è´¥: {e}\")\n    print(\"=\"*50)\n\n# --------------------------\n# 5. ä½¿ç”¨ Kaggle Input çš„æ¨¡å‹ (é€šè¿‡ç¬¦å·é“¾æ¥)\n# --------------------------\nkaggle_input_dir = \"/kaggle/input\"\n\nprint(\"\\nä½¿ç”¨æœ¬åœ° Kaggle Input æ¨¡å‹ç›®å½•:\", kaggle_input_dir)\n\n# åˆ›å»ºæ¨¡å‹ç›®å½•\nmodel_dirs = {\n    \"diffusion_models\": \"./models/diffusion_models\",\n    \"text_encoders\": \"./models/text_encoders\",\n    \"vae\": \"./models/vae\",\n    \"loras\": \"./models/loras\",\n    \"clip_vision\":\"./models/clip_vision\"\n}\n\nfor dir_path in model_dirs.values():\n    os.makedirs(dir_path, exist_ok=True)\n\n# ä½¿ç”¨ç¬¦å·é“¾æ¥ä»£æ›¿å¤åˆ¶æ–‡ä»¶\nprint(\"\\nåˆ›å»ºæ¨¡å‹æ–‡ä»¶ç¬¦å·é“¾æ¥ (èŠ‚çœå­˜å‚¨ç©ºé—´)...\")\nprint(\"=\"*60)\n\nlink_map = {\n    \"wan-animate-gguf-text-encoder\": \"./models/text_encoders\",\n    \"wan-animate-vae\": \"./models/vae\", \n    \"wan-animate-q3-k-m-gguf\": \"./models/unet\",\n    \"wan-animate-loras\": \"./models/loras\",\n    \"wan-animate-clip-vision\":\"./models/clip_vision\"\n}\n\nfor src_name, dst_path in link_map.items():\n    src_path = f\"{kaggle_input_dir}/{src_name}\"\n    if os.path.exists(src_path):\n        print(f\"\\nå¤„ç†: {src_name}\")\n        try:\n            # åˆ—å‡ºæºç›®å½•ä¸­çš„æ–‡ä»¶\n            files = os.listdir(src_path)\n            if not files:\n                print(f\"  âš  ç©ºç›®å½•: {src_name}\")\n                continue\n            \n            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç¬¦å·é“¾æ¥\n            for file in files:\n                src_file = os.path.join(src_path, file)\n                dst_file = os.path.join(dst_path, file)\n                \n                # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤\n                if os.path.exists(dst_file) or os.path.islink(dst_file):\n                    os.remove(dst_file)\n                    print(f\"  - åˆ é™¤æ—§é“¾æ¥: {file}\")\n                \n                # åˆ›å»ºç¬¦å·é“¾æ¥\n                os.symlink(src_file, dst_file)\n                print(f\"  âœ“ é“¾æ¥: {file}\")\n                \n        except Exception as e:\n            print(f\"  âœ— é”™è¯¯: {e}\")\n    else:\n        print(f\"  âš  æœªæ‰¾åˆ°: {src_name}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"æ¨¡å‹æ–‡ä»¶é“¾æ¥åˆ—è¡¨:\")\nprint(\"-\" * 50)\nfor name, path in model_dirs.items():\n    print(f\"\\n{name}:\")\n    !ls -lh {path}/ 2>/dev/null || echo \"  (ç©º)\"\n\n# éªŒè¯ç¬¦å·é“¾æ¥\nprint(\"\\néªŒè¯ç¬¦å·é“¾æ¥...\")\nfor name, path in model_dirs.items():\n    if os.path.exists(path):\n        files = os.listdir(path)\n        for file in files:\n            full_path = os.path.join(path, file)\n            if os.path.islink(full_path):\n                target = os.readlink(full_path)\n                print(f\"  âœ“ {file} -> {target}\")\n\n# --------------------------\n# 6. å®‰è£…æ‰€æœ‰å¿…éœ€æ’ä»¶\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"å®‰è£… ComfyUI æ’ä»¶...\")\nprint(\"=\"*60)\n\nos.makedirs(\"custom_nodes\", exist_ok=True)\n%cd custom_nodes\n\n# Complete list of plugins including Kijai workflow requirements\nall_plugins = {\n    # Core plugins\n    \"ComfyUI-Manager\": \"https://github.com/ltdrdata/ComfyUI-Manager.git\",\n    \"ComfyUI-GGUF\": \"https://github.com/city96/ComfyUI-GGUF.git\",\n    \"ComfyUI-WanVideoWrapper\": \"https://github.com/kijai/ComfyUI-WanVideoWrapper.git\",\n    \n    # Kijai workflow requirements\n    \"ComfyUI-KJNodes\": \"https://github.com/kijai/ComfyUI-KJNodes.git\",\n    \"comfyui_controlnet_aux\": \"https://github.com/Fannovel16/comfyui_controlnet_aux.git\",\n    \"ComfyUI-VideoHelperSuite\": \"https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git\",\n    \"ComfyUI-segment-anything-2\": \"https://github.com/kijai/ComfyUI-segment-anything-2.git\",\n    \"ComfyUI-Advanced-ControlNet\": \"https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git\",\n    \"comfyui-tooling-nodes\": \"https://github.com/Acly/comfyui-tooling-nodes.git\",\n    \"ComfyUI_essentials\": \"https://github.com/cubiq/ComfyUI_essentials.git\",\n    \n    # Additional required nodes\n    \"cg-use-everywhere\": \"https://github.com/chrisgoringe/cg-use-everywhere.git\",\n    \"was-node-suite-comfyui\": \"https://github.com/WASasquatch/was-node-suite-comfyui.git\",\n    \"ComfyUI-Custom-Scripts\": \"https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git\",\n    \"ComfyUI-Frame-Interpolation\": \"https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git\",\n    \"rgthree-comfy\": \"https://github.com/rgthree/rgthree-comfy.git\",\n    \"ComfyMath\": \"https://github.com/evanspearman/ComfyMath.git\",\n    \"ComfyUI-Easy-Use\": \"https://github.com/yolain/ComfyUI-Easy-Use.git\",\n    \"comfyui-mixlab-nodes\": \"https://github.com/MixLabPro/comfyui-mixlab-nodes.git\"\n}\n\nfor plugin_name, plugin_url in all_plugins.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"å¤„ç†: {plugin_name}\")\n    print(f\"{'='*60}\")\n    \n    if not os.path.exists(plugin_name):\n        print(f\"  â†’ å…‹éš† {plugin_name}...\")\n        !git clone {plugin_url}\n        \n        # Install requirements\n        req_file = f\"{plugin_name}/requirements.txt\"\n        if os.path.exists(req_file):\n            print(f\"  â†’ å®‰è£…ä¾èµ–...\")\n            !pip install -q -r {req_file}\n            \n        print(f\"  âœ“ {plugin_name} å®Œæˆ\")\n    else:\n        print(f\"  â†’ {plugin_name} å·²å­˜åœ¨ï¼Œæ›´æ–°ä¸­...\")\n        %cd {plugin_name}\n        !git pull -q\n        \n        # Update requirements\n        if os.path.exists(\"requirements.txt\"):\n            !pip install -q -r requirements.txt\n        %cd ..\n        print(f\"  âœ“ {plugin_name} æ›´æ–°å®Œæˆ\")\n\n%cd ..\nprint(\"\\n\" + \"=\"*60)\nprint(f\"âœ“ æ‰€æœ‰æ’ä»¶å®‰è£…å®Œæˆï¼\")\nprint(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\nprint(\"=\"*60)\n\n# --------------------------\n# 6.5 é…ç½® ComfyUI å¤šGPUæ”¯æŒ\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"é…ç½® ComfyUI å¤šGPUæ”¯æŒ...\")\nprint(\"=\"*60)\n\n# Remove or fix the extra_model_paths.yaml file to prevent startup errors\nconfig_file = \"extra_model_paths.yaml\"\nif os.path.exists(config_file):\n    os.remove(config_file)\n    print(f\"âœ“ å·²åˆ é™¤æ—§é…ç½®æ–‡ä»¶: {config_file}\")\n\n# ComfyUI will use default paths, which works better with multi-GPU\nprint(\"âœ“ ä½¿ç”¨é»˜è®¤é…ç½® (è‡ªåŠ¨å¤šGPUæ”¯æŒ)\")\nprint(\"=\"*60)\n\n# Suppress warnings in environment\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n\n# Change to ComfyUI directory\n%cd /kaggle/working/ComfyUI\n\nprint(\"\\nğŸš€ å¯åŠ¨ ComfyUI æœåŠ¡å™¨ (å¤šGPUæ¨¡å¼)...\")\n\n# Check GPU count one more time\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    if num_gpus > 1:\n        print(f\"âœ“ å¯ç”¨ {num_gpus} GPU æ¨¡å¼\")\n        print(f\"  CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'all')}\")\n    print()\nexcept:\n    pass\n\n# --------------------------\n# 7. å¯åŠ¨ ComfyUI ä½œä¸ºåå°è¿›ç¨‹\n# --------------------------\nimport subprocess\nimport time\nimport requests\nimport sys\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸš€ å¯åŠ¨ ComfyUI æœåŠ¡å™¨ (åå°è¿›ç¨‹æ¨¡å¼)...\")\nprint(\"=\"*60)\n\n# Ensure we're in the ComfyUI directory\nos.chdir('/kaggle/working/ComfyUI')\nprint(f\"å½“å‰ç›®å½•: {os.getcwd()}\")\n\n# Configure launch arguments\ncomfy_args = [\n    sys.executable,  # Use current Python interpreter\n    'main.py',\n    '--listen', '0.0.0.0',\n    '--port', '8188',\n    '--preview-method', 'auto'\n]\n\n# Add multi-GPU support if available\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    if num_gpus > 1:\n        print(f\"âœ“ é…ç½®å¤šGPUæ¨¡å¼ ({num_gpus} GPUs)\")\n        # ComfyUI will automatically use all available GPUs\nexcept:\n    pass\n\n# Start ComfyUI as background subprocess\nprint(f\"\\nå¯åŠ¨å‘½ä»¤: {' '.join(comfy_args)}\")\nprint(\"=\"*60)\n\ncomfy_process = subprocess.Popen(\n    comfy_args,\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE,\n    cwd='/kaggle/working/ComfyUI',\n    bufsize=1,\n    universal_newlines=True\n)\n\nprint(f\"âœ“ ComfyUI è¿›ç¨‹å·²å¯åŠ¨\")\nprint(f\"  PID: {comfy_process.pid}\")\nprint(f\"  çŠ¶æ€: {'è¿è¡Œä¸­' if comfy_process.poll() is None else 'å·²åœæ­¢'}\")\n\n# --------------------------\n# 8. ç­‰å¾… ComfyUI å°±ç»ª\n# --------------------------\ndef wait_for_comfyui(max_attempts=60, delay=2):\n    \"\"\"ç­‰å¾… ComfyUI æœåŠ¡å™¨å°±ç»ª\"\"\"\n    print(f\"\\nâ³ ç­‰å¾… ComfyUI å¯åŠ¨ (æœ€å¤š {max_attempts * delay} ç§’)...\")\n    print(\"-\" * 60)\n    \n    for i in range(max_attempts):\n        # Check if process is still running\n        if comfy_process.poll() is not None:\n            print(f\"\\nâœ— ComfyUI è¿›ç¨‹æ„å¤–ç»ˆæ­¢!\")\n            print(\"\\næœ€åçš„è¾“å‡º:\")\n            if comfy_process.stdout:\n                print(comfy_process.stdout.read())\n            if comfy_process.stderr:\n                print(\"\\né”™è¯¯è¾“å‡º:\")\n                print(comfy_process.stderr.read())\n            return False\n        \n        try:\n            # Try to connect to ComfyUI API\n            response = requests.get(\n                \"http://127.0.0.1:8188/system_stats\",\n                timeout=2\n            )\n            \n            if response.status_code == 200:\n                print(f\"\\nâœ“ ComfyUI å·²å°±ç»ª! (è€—æ—¶ {(i+1) * delay} ç§’)\")\n                print(\"-\" * 60)\n                \n                # Print system stats\n                try:\n                    stats = response.json()\n                    print(\"\\nç³»ç»ŸçŠ¶æ€:\")\n                    if 'system' in stats:\n                        sys_info = stats['system']\n                        print(f\"  â€¢ OS: {sys_info.get('os', 'N/A')}\")\n                        print(f\"  â€¢ Python: {sys_info.get('python_version', 'N/A')}\")\n                    \n                    if 'devices' in stats:\n                        devices = stats['devices']\n                        print(f\"\\n  â€¢ GPU è®¾å¤‡:\")\n                        for i, device in enumerate(devices):\n                            print(f\"    - GPU {i}: {device.get('name', 'N/A')}\")\n                            vram_total = device.get('vram_total', 0) / (1024**3)\n                            print(f\"      VRAM: {vram_total:.2f} GB\")\n                except:\n                    pass\n                \n                print(\"=\"*60)\n                return True\n                \n        except requests.exceptions.RequestException:\n            pass\n        except Exception as e:\n            pass\n        \n        # Progress indicator\n        time.sleep(delay)\n        if (i + 1) % 5 == 0:\n            print(f\"  å°è¯• {i+1}/{max_attempts} - ä»åœ¨å¯åŠ¨ä¸­...\")\n    \n    print(f\"\\nâš ï¸ è¶…æ—¶: ComfyUI æœªèƒ½åœ¨ {max_attempts * delay} ç§’å†…å¯åŠ¨\")\n    print(\"\\næ£€æŸ¥è¿›ç¨‹çŠ¶æ€...\")\n    print(f\"  è¿›ç¨‹çŠ¶æ€: {'è¿è¡Œä¸­' if comfy_process.poll() is None else 'å·²åœæ­¢'}\")\n    \n    return False\n\n# Wait for ComfyUI to be ready\nif wait_for_comfyui():\n    print(\"\\nğŸ‰ ComfyUI æœåŠ¡å™¨è¿è¡Œæ­£å¸¸!\")\n    print(f\"    â†’ æœ¬åœ°è®¿é—®: http://127.0.0.1:8188\")\n    print(f\"    â†’ è¿›ç¨‹ PID: {comfy_process.pid}\")\n    print(\"\\nâœ“ å¯ä»¥ç»§ç»­è¿è¡Œä¸‹ä¸€ä¸ªå•å…ƒæ ¼å¯åŠ¨ Gradio\")\nelse:\n    print(\"\\nâš ï¸  ComfyUI å¯åŠ¨å¯èƒ½é‡åˆ°é—®é¢˜\")\n    print(\"    â†’ å»ºè®®æ£€æŸ¥ä¸‹é¢çš„æ—¥å¿—è¾“å‡º\")\n    print(\"    â†’ æˆ–è¿è¡Œè°ƒè¯•å•å…ƒæ ¼æŸ¥çœ‹è¯¦ç»†é”™è¯¯\")\n\nprint(\"=\"*60)\n\n# --------------------------\n# 9. å¯é€‰: å®æ—¶æŸ¥çœ‹ ComfyUI æ—¥å¿—\n# --------------------------\n# å¦‚æœéœ€è¦æŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼Œå¯ä»¥è¿è¡Œè¿™ä¸ªå•å…ƒæ ¼:\n\nimport threading\n\ndef stream_output(pipe, label):\n    '''å®æ—¶æ‰“å°è¿›ç¨‹è¾“å‡º'''\n    for line in iter(pipe.readline, ''):\n        if line:\n            print(f\"[{label}] {line.rstrip()}\")\n\n# åˆ›å»ºæ—¥å¿—çº¿ç¨‹\nstdout_thread = threading.Thread(\n    target=stream_output, \n    args=(comfy_process.stdout, \"STDOUT\"),\n    daemon=True\n)\nstderr_thread = threading.Thread(\n    target=stream_output,\n    args=(comfy_process.stderr, \"STDERR\"),\n    daemon=True\n)\n\nstdout_thread.start()\nstderr_thread.start()\n\nprint(\"âœ“ æ—¥å¿—ç›‘æ§å·²å¯åŠ¨ (åå°è¿è¡Œ)\")\n\n# --------------------------\n# 10. è°ƒè¯•å•å…ƒæ ¼ (å¯é€‰)\n# --------------------------\n# å¦‚æœ ComfyUI å¯åŠ¨å¤±è´¥ï¼Œè¿è¡Œè¿™ä¸ªæ¥æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯:\n\nprint(\"=\"*60)\nprint(\"ComfyUI è¿›ç¨‹è¯Šæ–­\")\nprint(\"=\"*60)\n\nprint(f\"\\nè¿›ç¨‹ PID: {comfy_process.pid}\")\nprint(f\"è¿›ç¨‹çŠ¶æ€: {comfy_process.poll()}\")\nprint(f\"è¿è¡Œä¸­: {comfy_process.poll() is None}\")\n\nif comfy_process.poll() is not None:\n    print(\"\\nâš ï¸  è¿›ç¨‹å·²åœæ­¢\")\n    \n    print(\"\\næ ‡å‡†è¾“å‡º:\")\n    print(\"-\" * 60)\n    if comfy_process.stdout:\n        stdout = comfy_process.stdout.read()\n        print(stdout if stdout else \"(æ— è¾“å‡º)\")\n    \n    print(\"\\næ ‡å‡†é”™è¯¯:\")\n    print(\"-\" * 60)\n    if comfy_process.stderr:\n        stderr = comfy_process.stderr.read()\n        print(stderr if stderr else \"(æ— é”™è¯¯)\")\nelse:\n    print(\"\\nâœ“ è¿›ç¨‹ä»åœ¨è¿è¡Œ\")\n    \n    # Test API connection\n    try:\n        response = requests.get(\"http://127.0.0.1:8188/system_stats\", timeout=2)\n        print(f\"\\nâœ“ API å“åº”: {response.status_code}\")\n        print(response.json())\n    except Exception as e:\n        print(f\"\\nâœ— API è¿æ¥å¤±è´¥: {e}\")\n\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GRADIO + COMFYUI API (In case if Localtunnel connection is unstable)\n\n!pip install gradio requests websocket-client pillow\n\nimport json\nimport requests\nimport gradio as gr\nimport websocket\nimport uuid\nimport urllib.request\nimport urllib.parse\nfrom PIL import Image\nimport io\nimport os\nimport time\n\nclass ComfyUIAPI:\n    def __init__(self, server_address=\"127.0.0.1:8188\"):\n        self.server_address = server_address\n        self.client_id = str(uuid.uuid4())\n        \n    def queue_prompt(self, prompt):\n        \"\"\"Queue a prompt to ComfyUI\"\"\"\n        p = {\"prompt\": prompt, \"client_id\": self.client_id}\n        data = json.dumps(p).encode('utf-8')\n        req = urllib.request.Request(f\"http://{self.server_address}/prompt\", data=data)\n        return json.loads(urllib.request.urlopen(req).read())\n    \n    def upload_image(self, image_path, subfolder=\"\", overwrite=False):\n        \"\"\"Upload an image to ComfyUI\"\"\"\n        with open(image_path, 'rb') as f:\n            files = {'image': f}\n            data = {\n                'subfolder': subfolder,\n                'overwrite': str(overwrite).lower()\n            }\n            response = requests.post(\n                f\"http://{self.server_address}/upload/image\",\n                files=files,\n                data=data\n            )\n        return response.json()\n    \n    def upload_video(self, video_path, subfolder=\"\", overwrite=True):\n        \"\"\"Upload a video to ComfyUI\"\"\"\n        with open(video_path, 'rb') as f:\n            files = {'image': (os.path.basename(video_path), f, 'video/mp4')}\n            data = {\n                'subfolder': subfolder,\n                'overwrite': str(overwrite).lower(),\n                'type': 'input'\n            }\n            response = requests.post(\n                f\"http://{self.server_address}/upload/image\",\n                files=files,\n                data=data\n            )\n        return response.json()\n    \n    def get_history(self, prompt_id):\n        \"\"\"Get the execution history for a prompt\"\"\"\n        req = urllib.request.Request(f\"http://{self.server_address}/history/{prompt_id}\")\n        return json.loads(urllib.request.urlopen(req).read())\n    \n    def get_image(self, filename, subfolder, folder_type):\n        \"\"\"Download an image from ComfyUI\"\"\"\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        url = f\"http://{self.server_address}/view?{url_values}\"\n        with urllib.request.urlopen(url) as response:\n            return response.read()\n    \n    def track_progress(self, prompt_id, progress_callback=None):\n        \"\"\"Track workflow execution progress via WebSocket\"\"\"\n        ws = websocket.WebSocket()\n        ws.connect(f\"ws://{self.server_address}/ws?clientId={self.client_id}\")\n        \n        while True:\n            out = ws.recv()\n            if isinstance(out, str):\n                message = json.loads(out)\n                \n                if message['type'] == 'progress' and progress_callback:\n                    data = message['data']\n                    progress_callback(data.get('value', 0), data.get('max', 100))\n                \n                if message['type'] == 'executing':\n                    data = message['data']\n                    if data['node'] is None and data['prompt_id'] == prompt_id:\n                        break\n        ws.close()\n\nclass WanVideoGradioApp:\n    def __init__(self):\n        self.api = ComfyUIAPI()\n        self.workflow = None\n        \n    def load_workflow(self, workflow_file):\n        \"\"\"Load the WanVideo workflow JSON file\"\"\"\n        try:\n            if workflow_file is None:\n                return \"âš  Please upload a workflow file\"\n                \n            with open(workflow_file.name, 'r') as f:\n                self.workflow = json.load(f)\n            return f\"âœ“ Workflow loaded successfully! Found {len(self.workflow)} nodes.\\nReady to process videos.\"\n        except Exception as e:\n            return f\"âœ— Error loading workflow: {str(e)}\"\n    \n    def run_workflow(self, prompt_text, negative_prompt, input_image, input_video, \n                    length_seconds, framerate, resolution, interpolation_factor, seed):\n        \"\"\"Execute the WanVideo workflow with provided inputs\"\"\"\n        if not self.workflow:\n            return \"âš  Please load a workflow first!\", None, None\n        \n        try:\n            status_updates = []\n            \n            # Upload image\n            if input_image:\n                status_updates.append(\"ğŸ“¤ Uploading image...\")\n                img_result = self.api.upload_image(input_image)\n                self.workflow[\"64\"][\"inputs\"][\"image\"] = img_result['name']\n                status_updates.append(f\"âœ“ Image uploaded: {img_result['name']}\")\n            \n            # Upload video\n            if input_video:\n                status_updates.append(\"ğŸ“¤ Uploading video...\")\n                vid_result = self.api.upload_video(input_video)\n                self.workflow[\"13\"][\"inputs\"][\"video\"] = vid_result['name']\n                status_updates.append(f\"âœ“ Video uploaded: {vid_result['name']}\")\n            \n            # Update text prompts\n            if prompt_text:\n                self.workflow[\"124\"][\"inputs\"][\"text\"] = prompt_text\n            if negative_prompt:\n                self.workflow[\"122\"][\"inputs\"][\"text\"] = negative_prompt\n            \n            # Update parameters\n            self.workflow[\"28\"][\"inputs\"][\"value\"] = float(length_seconds)\n            self.workflow[\"30\"][\"inputs\"][\"value\"] = float(framerate)\n            self.workflow[\"32\"][\"inputs\"][\"value\"] = int(resolution)\n            self.workflow[\"29\"][\"inputs\"][\"value\"] = int(interpolation_factor)\n            self.workflow[\"90\"][\"inputs\"][\"seed\"] = int(seed)\n            \n            status_updates.append(\"âš™ï¸ Starting workflow execution...\")\n            \n            # Queue the prompt\n            result = self.api.queue_prompt(self.workflow)\n            prompt_id = result['prompt_id']\n            status_updates.append(f\"âœ“ Workflow queued (ID: {prompt_id[:8]}...)\")\n            \n            # Track progress\n            status_updates.append(\"ğŸ”„ Processing... This may take several minutes.\")\n            self.api.track_progress(prompt_id)\n            \n            status_updates.append(\"âœ“ Workflow completed!\")\n            status_updates.append(\"ğŸ“¦ Retrieving outputs...\")\n            \n            # Get output\n            time.sleep(2)  # Wait for files to be written\n            history = self.api.get_history(prompt_id)[prompt_id]\n            \n            # Get output images/videos\n            output_images = []\n            output_info = []\n            \n            for node_id in history['outputs']:\n                node_output = history['outputs'][node_id]\n                \n                # Get images\n                if 'images' in node_output:\n                    for image in node_output['images']:\n                        try:\n                            image_data = self.api.get_image(\n                                image['filename'], \n                                image['subfolder'], \n                                image['type']\n                            )\n                            img = Image.open(io.BytesIO(image_data))\n                            output_images.append(img)\n                            output_info.append(f\"Image: {image['filename']}\")\n                        except:\n                            pass\n                \n                # Get videos\n                if 'gifs' in node_output:\n                    for video in node_output['gifs']:\n                        output_info.append(f\"Video: {video['filename']}\")\n            \n            status_updates.append(f\"âœ“ Found {len(output_info)} outputs\")\n            \n            final_status = \"\\n\".join(status_updates)\n            \n            if output_images:\n                return final_status, output_images[0], \"\\n\".join(output_info)\n            else:\n                return final_status + \"\\n\\nâœ“ Video generation complete! Check ComfyUI output folder.\", None, \"\\n\".join(output_info)\n                \n        except Exception as e:\n            error_msg = f\"âœ— Error executing workflow: {str(e)}\"\n            import traceback\n            error_msg += f\"\\n\\nDetails:\\n{traceback.format_exc()}\"\n            return error_msg, None, None\n\n# Initialize the app\napp = WanVideoGradioApp()\n\n# Create Gradio interface\nwith gr.Blocks(title=\"WanVideo ComfyUI Controller\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"\"\"\n    # ğŸ¬ WanVideo Animation Controller\n    ### Control WanVideo workflow via ComfyUI API with Gradio\n    \"\"\")\n    \n    with gr.Row():\n        workflow_file = gr.File(\n            label=\"ğŸ“ Upload Workflow JSON (wan_2_2_animate.json)\",\n            file_types=[\".json\"]\n        )\n        load_btn = gr.Button(\"Load Workflow\", variant=\"primary\", size=\"sm\")\n    \n    workflow_status = gr.Textbox(\n        label=\"Workflow Status\",\n        interactive=False,\n        lines=2\n    )\n    \n    gr.Markdown(\"---\")\n    gr.Markdown(\"### ğŸ¨ Input Configuration\")\n    \n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"**ğŸ“ Text Inputs**\")\n            prompt_text = gr.Textbox(\n                label=\"Positive Prompt\",\n                placeholder=\"Describe the animation you want...\",\n                lines=3,\n                value=\"Shrek is dancing.\"\n            )\n            negative_prompt = gr.Textbox(\n                label=\"Negative Prompt\",\n                placeholder=\"What to avoid in the animation...\",\n                lines=3,\n                value=\"overexposed, static, blurry details, low quality\"\n            )\n        \n        with gr.Column():\n            gr.Markdown(\"**ğŸ–¼ï¸ Media Inputs**\")\n            input_image = gr.Image(\n                label=\"Reference Image\",\n                type=\"filepath\",\n                height=200\n            )\n            input_video = gr.Video(\n                label=\"Input Video (Optional)\",\n                height=200\n            )\n    \n    gr.Markdown(\"### âš™ï¸ Generation Parameters\")\n    \n    with gr.Row():\n        length_seconds = gr.Slider(\n            minimum=1,\n            maximum=30,\n            value=7,\n            step=1,\n            label=\"ğŸ¬ Length (Seconds)\"\n        )\n        framerate = gr.Slider(\n            minimum=8,\n            maximum=60,\n            value=16,\n            step=1,\n            label=\"ğŸ¦ Framerate (FPS)\"\n        )\n    \n    with gr.Row():\n        resolution = gr.Slider(\n            minimum=256,\n            maximum=1024,\n            value=480,\n            step=64,\n            label=\"ğŸ”² Resolution (Width)\"\n        )\n        interpolation_factor = gr.Slider(\n            minimum=1,\n            maximum=4,\n            value=2,\n            step=1,\n            label=\"ğŸ”€ Interpolation Factor\"\n        )\n    \n    seed = gr.Number(\n        label=\"ğŸ² Seed\",\n        value=777,\n        precision=0\n    )\n    \n    run_btn = gr.Button(\"â–¶ Generate Animation\", variant=\"primary\", size=\"lg\")\n    \n    gr.Markdown(\"---\")\n    gr.Markdown(\"### ğŸ“Š Results\")\n    \n    with gr.Row():\n        with gr.Column():\n            execution_status = gr.Textbox(\n                label=\"Execution Log\",\n                interactive=False,\n                lines=10\n            )\n        with gr.Column():\n            output_image = gr.Image(\n                label=\"Preview Frame\"\n            )\n    \n    output_files = gr.Textbox(\n        label=\"Output Files\",\n        interactive=False,\n        lines=3\n    )\n    \n    gr.Markdown(\"\"\"\n    ---\n    ### ğŸ“– Instructions:\n    \n    1. **Load Workflow**: Upload the `wan_2_2_animate.json` file\n    2. **Set Prompts**: Describe the animation you want to create\n    3. **Upload Media**: \n       - **Required**: Reference image (character/subject)\n       - **Optional**: Input video for motion reference\n    4. **Adjust Parameters**: \n       - Length: Duration in seconds\n       - Framerate: Higher = smoother but slower to generate\n       - Resolution: Output width (height auto-calculated)\n       - Interpolation: Multiplier for frame interpolation (2 = double frames)\n    5. **Generate**: Click \"Generate Animation\" and wait\n    \n    **Output Location**: Check your ComfyUI `output` folder for the final videos:\n    - `Wanimate_*.mp4` - Base animation\n    - `Wanimate_Interpolated_*.mp4` - Interpolated high-FPS version\n    \n    **Note**: Make sure ComfyUI is running on `127.0.0.1:8188` with all required models loaded.\n    \"\"\")\n    \n    # Event handlers\n    load_btn.click(\n        fn=app.load_workflow,\n        inputs=[workflow_file],\n        outputs=[workflow_status]\n    )\n    \n    run_btn.click(\n        fn=app.run_workflow,\n        inputs=[\n            prompt_text,\n            negative_prompt,\n            input_image,\n            input_video,\n            length_seconds,\n            framerate,\n            resolution,\n            interpolation_factor,\n            seed\n        ],\n        outputs=[execution_status, output_image, output_files]\n    )\n    \n    # Load example\n    gr.Examples(\n        examples=[\n            [\"A person dancing energetically\", \"static, blurry, low quality\", 5, 16, 480, 2, 777],\n            [\"Character walking forward confidently\", \"overexposed, static, ugly\", 7, 16, 512, 2, 123],\n        ],\n        inputs=[prompt_text, negative_prompt, length_seconds, framerate, resolution, interpolation_factor, seed],\n    )\n\n\ndemo.launch(share=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}