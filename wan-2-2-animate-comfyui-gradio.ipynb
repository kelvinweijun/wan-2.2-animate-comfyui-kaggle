{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13666598,"sourceType":"datasetVersion","datasetId":8689334},{"sourceId":13708953,"sourceType":"datasetVersion","datasetId":8721020},{"sourceId":13726076,"sourceType":"datasetVersion","datasetId":8732821},{"sourceId":13726184,"sourceType":"datasetVersion","datasetId":8732885},{"sourceId":13726280,"sourceType":"datasetVersion","datasetId":8732945},{"sourceId":13726587,"sourceType":"datasetVersion","datasetId":8733161},{"sourceId":13727491,"sourceType":"datasetVersion","datasetId":8733722},{"sourceId":13728542,"sourceType":"datasetVersion","datasetId":8734451},{"sourceId":13728642,"sourceType":"datasetVersion","datasetId":8734522},{"sourceId":13728722,"sourceType":"datasetVersion","datasetId":8734578},{"sourceId":13742285,"sourceType":"datasetVersion","datasetId":8743983},{"sourceId":13743579,"sourceType":"datasetVersion","datasetId":8744930},{"sourceId":13765803,"sourceType":"datasetVersion","datasetId":8760693},{"sourceId":13768043,"sourceType":"datasetVersion","datasetId":8762389},{"sourceId":13792505,"sourceType":"datasetVersion","datasetId":8780895}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport shutil\nimport warnings\nimport time\n\n# Suppress future warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# Create constraints file\n!echo \"numpy<2.0\" > /kaggle/working/constraints.txt\n\n# Set environment variable for the entire notebook\nimport os\nos.environ['PIP_CONSTRAINT'] = '/kaggle/working/constraints.txt'\n\n# --------------------------\n# 0. Ê∏ÖÁêÜÊóßËøõÁ®ã\n# --------------------------\nprint(\"Ê∏ÖÁêÜÊóßËøõÁ®ã...\")\n!pkill -f 'python main.py' || true\n!pkill -f 'pinggy' || true\n\n# --------------------------\n# 0.5 Ê£ÄÊµãÂíåÈÖçÁΩÆÂ§öGPU\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"Ê£ÄÊµã GPU ÈÖçÁΩÆ...\")\nprint(\"=\"*60)\n\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    print(f\"‚úì Ê£ÄÊµãÂà∞ {num_gpus} ‰∏™ GPU\")\n    \n    for i in range(num_gpus):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        props = torch.cuda.get_device_properties(i)\n        print(f\"    - ÊòæÂ≠ò: {props.total_memory / 1024**3:.2f} GB\")\n    \n    # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè‰ª•ÂêØÁî®Â§öGPU\n    if num_gpus > 1:\n        print(f\"\\n‚úì ÈÖçÁΩÆÂ§öGPUÊ®°Âºè ({num_gpus} GPUs)\")\n        os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, range(num_gpus)))\n    else:\n        print(\"\\n‚ö† ‰ªÖÊ£ÄÊµãÂà∞1‰∏™GPU\")\n        \nexcept Exception as e:\n    print(f\"‚úó GPUÊ£ÄÊµãÂ§±Ë¥•: {e}\")\n\nprint(\"=\"*60)\n\n# --------------------------\n# 1. Á≥ªÁªü‰æùËµñ\n# --------------------------\nprint(\"ÂÆâË£ÖÁ≥ªÁªüÂ∫ì...\")\n!apt-get update -qq\n!apt-get install -y -qq libgl1 libglib2.0-0 ffmpeg\n\n# --------------------------\n# 2. ÂÖãÈöÜ ComfyUI\n# --------------------------\nprint(\"ÂÖãÈöÜ ComfyUI ‰ªìÂ∫ì...\")\nif not os.path.exists(\"ComfyUI\"):\n    !git clone https://github.com/comfyanonymous/ComfyUI.git\n\n%cd ComfyUI\nprint(f\"ÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï: {os.getcwd()}\")\nprint(\"Êõ¥Êñ∞ ComfyUI...\")\n!git pull\n\n# --------------------------\n# 3. ÂÆâË£Ö Python Â∫ì (‰ºòÂåñÁâàÊú¨ÁªÑÂêà)\n# --------------------------\nprint(\"ÂÆâË£ÖÈ¢ùÂ§ñ‰æùËµñ...\")\n!pip install -q mediapipe\n!pip uninstall onnxruntime -y\n!pip install onnxruntime-gpu\n\nimport onnxruntime as ort\nprint(ort.get_available_providers())\n# Should show: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n\n# SAM-2 needs to be installed from git\n!pip install -q git+https://github.com/facebookresearch/segment-anything-2.git\n\nprint(\"Âç∏ËΩΩ‰∏çÂÖºÂÆπÂ∫ì...\")\n!pip uninstall -y torch torchvision torchaudio xformers\n\nprint(\"ÂÆâË£ÖÊúÄÊñ∞ PyTorch nightly (WanVideoWrapper Ë¶ÅÊ±Ç 2.7.0.dev20250226+)...\")\n# !pip install --pre --upgrade --extra-index-url https://download.pytorch.org/whl/nightly/cu121 torch torchvision torchaudio\n!pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu128\n\nprint(\"ÂÆâË£ÖÂÖºÂÆπÁöÑ xformers...\")\n!pip install -q xformers\n\nprint(\"ÂÆâË£Ö ComfyUI ÂÖ∂‰Ωô‰æùËµñ...\")\n\n# Downgrade numpy to avoid incompatibility with custom nodes\n\n!pip install -q -r requirements.txt --no-deps\n!pip install -q torchsde einops transformers safetensors aiohttp accelerate pyyaml opencv-python pillow scipy imageio[ffmpeg] moviepy huggingface_hub gguf ftfy\n!pip install -q pydantic-settings python-dotenv\n\n# --------------------------\n# 4. È™åËØÅÂÆâË£Ö\n# --------------------------\nprint(\"\\n\" + \"=\"*50)\nprint(\"È™åËØÅ PyTorch Âíå xformers...\")\nprint(\"=\"*50)\ntry:\n    import torch\n    import torchvision\n    import xformers\n    import xformers.ops\n    \n    print(f\"‚úì PyTorch: {torch.__version__}\")\n    print(f\"‚úì TorchVision: {torchvision.__version__}\")\n    print(f\"‚úì xformers: {xformers.__version__}\")\n    print(f\"‚úì CUDA ÂèØÁî®: {torch.cuda.is_available()}\")\n    \n    if torch.cuda.is_available():\n        num_gpus = torch.cuda.device_count()\n        print(f\"‚úì GPU Êï∞Èáè: {num_gpus}\")\n        for i in range(num_gpus):\n            print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n        print(f\"‚úì CUDA ÁâàÊú¨: {torch.version.cuda}\")\n    \n    # È™åËØÅ RMSNorm ÂèØÁî®ÊÄß\n    if hasattr(torch.nn, 'RMSNorm'):\n        print(\"‚úì RMSNorm ÂèØÁî® (WanVideoWrapper Â∞ÜÊ≠£Â∏∏Â∑•‰Ωú)\")\n    else:\n        print(\"‚úó RMSNorm ‰∏çÂèØÁî®\")\n        \n    print(\"=\"*50)\nexcept Exception as e:\n    print(f\"‚úó È™åËØÅÂ§±Ë¥•: {e}\")\n    print(\"=\"*50)\n\n# --------------------------\n# 5. ‰ΩøÁî® Kaggle Input ÁöÑÊ®°Âûã (ÈÄöËøáÁ¨¶Âè∑ÈìæÊé•)\n# --------------------------\nkaggle_input_dir = \"/kaggle/input\"\n\nprint(\"\\n‰ΩøÁî®Êú¨Âú∞ Kaggle Input Ê®°ÂûãÁõÆÂΩï:\", kaggle_input_dir)\n\n# ÂàõÂª∫Ê®°ÂûãÁõÆÂΩï\nmodel_dirs = {\n    \"diffusion_models\": \"./models/diffusion_models\",\n    \"text_encoders\": \"./models/text_encoders\",\n    \"vae\": \"./models/vae\",\n    \"loras\": \"./models/loras\",\n    \"clip_vision\":\"./models/clip_vision\"\n}\n\nfor dir_path in model_dirs.values():\n    os.makedirs(dir_path, exist_ok=True)\n\n# ‰ΩøÁî®Á¨¶Âè∑ÈìæÊé•‰ª£ÊõøÂ§çÂà∂Êñá‰ª∂\nprint(\"\\nÂàõÂª∫Ê®°ÂûãÊñá‰ª∂Á¨¶Âè∑ÈìæÊé• (ËäÇÁúÅÂ≠òÂÇ®Á©∫Èó¥)...\")\nprint(\"=\"*60)\n\nlink_map = {\n    \"wan-animate-gguf-text-encoder\": \"./models/text_encoders\",\n    \"wan-animate-vae\": \"./models/vae\", \n    \"wan-animate-q3-k-m-gguf\": \"./models/unet\",\n    \"wan-animate-loras\": \"./models/loras\",\n    \"wan-animate-clip-vision\":\"./models/clip_vision\"\n}\n\nfor src_name, dst_path in link_map.items():\n    src_path = f\"{kaggle_input_dir}/{src_name}\"\n    if os.path.exists(src_path):\n        print(f\"\\nÂ§ÑÁêÜ: {src_name}\")\n        try:\n            # ÂàóÂá∫Ê∫êÁõÆÂΩï‰∏≠ÁöÑÊñá‰ª∂\n            files = os.listdir(src_path)\n            if not files:\n                print(f\"  ‚ö† Á©∫ÁõÆÂΩï: {src_name}\")\n                continue\n            \n            # ‰∏∫ÊØè‰∏™Êñá‰ª∂ÂàõÂª∫Á¨¶Âè∑ÈìæÊé•\n            for file in files:\n                src_file = os.path.join(src_path, file)\n                dst_file = os.path.join(dst_path, file)\n                \n                # Â¶ÇÊûúÁõÆÊ†áÂ∑≤Â≠òÂú®ÔºåÂÖàÂà†Èô§\n                if os.path.exists(dst_file) or os.path.islink(dst_file):\n                    os.remove(dst_file)\n                    print(f\"  - Âà†Èô§ÊóßÈìæÊé•: {file}\")\n                \n                # ÂàõÂª∫Á¨¶Âè∑ÈìæÊé•\n                os.symlink(src_file, dst_file)\n                print(f\"  ‚úì ÈìæÊé•: {file}\")\n                \n        except Exception as e:\n            print(f\"  ‚úó ÈîôËØØ: {e}\")\n    else:\n        print(f\"  ‚ö† Êú™ÊâæÂà∞: {src_name}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Ê®°ÂûãÊñá‰ª∂ÈìæÊé•ÂàóË°®:\")\nprint(\"-\" * 50)\nfor name, path in model_dirs.items():\n    print(f\"\\n{name}:\")\n    !ls -lh {path}/ 2>/dev/null || echo \"  (Á©∫)\"\n\n# È™åËØÅÁ¨¶Âè∑ÈìæÊé•\nprint(\"\\nÈ™åËØÅÁ¨¶Âè∑ÈìæÊé•...\")\nfor name, path in model_dirs.items():\n    if os.path.exists(path):\n        files = os.listdir(path)\n        for file in files:\n            full_path = os.path.join(path, file)\n            if os.path.islink(full_path):\n                target = os.readlink(full_path)\n                print(f\"  ‚úì {file} -> {target}\")\n\n# --------------------------\n# 6. ÂÆâË£ÖÊâÄÊúâÂøÖÈúÄÊèí‰ª∂\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"ÂÆâË£Ö ComfyUI Êèí‰ª∂...\")\nprint(\"=\"*60)\n\nif os.path.exists(\"/kaggle/input/wan-animate-custom-nodes\"):\n    src = \"/kaggle/input/wan-animate-custom-nodes/custom_nodes\"\n    dest = \"/kaggle/working/ComfyUI/custom_nodes\"\n    \n    # Copy folder directly\n    shutil.copytree(src, dest, dirs_exist_ok=True)\n    \n    print(\"Custom nodes copied\")\n\n%cd custom_nodes\n\n# Complete list of plugins including Kijai workflow requirements\nall_plugins = {\n    # Core plugins\n    \"ComfyUI-Manager\": \"https://github.com/ltdrdata/ComfyUI-Manager.git\",\n    \"ComfyUI-GGUF\": \"https://github.com/city96/ComfyUI-GGUF.git\",\n    \"ComfyUI-WanVideoWrapper\": \"https://github.com/kijai/ComfyUI-WanVideoWrapper.git\",\n    \n    # Kijai workflow requirements\n    \"ComfyUI-KJNodes\": \"https://github.com/kijai/ComfyUI-KJNodes.git\",\n    \"comfyui_controlnet_aux\": \"https://github.com/Fannovel16/comfyui_controlnet_aux.git\",\n    \"ComfyUI-VideoHelperSuite\": \"https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git\",\n    \"ComfyUI-segment-anything-2\": \"https://github.com/kijai/ComfyUI-segment-anything-2.git\",\n    \"ComfyUI-Advanced-ControlNet\": \"https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet.git\",\n    \"comfyui-tooling-nodes\": \"https://github.com/Acly/comfyui-tooling-nodes.git\",\n    \"ComfyUI_essentials\": \"https://github.com/cubiq/ComfyUI_essentials.git\",\n    \n    # Additional required nodes\n    \"cg-use-everywhere\": \"https://github.com/chrisgoringe/cg-use-everywhere.git\",\n    \"was-node-suite-comfyui\": \"https://github.com/WASasquatch/was-node-suite-comfyui.git\",\n    \"ComfyUI-Custom-Scripts\": \"https://github.com/pythongosssss/ComfyUI-Custom-Scripts.git\",\n    \"ComfyUI-Frame-Interpolation\": \"https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git\",\n    \"rgthree-comfy\": \"https://github.com/rgthree/rgthree-comfy.git\",\n    \"ComfyMath\": \"https://github.com/evanspearman/ComfyMath.git\",\n    \"ComfyUI-Easy-Use\": \"https://github.com/yolain/ComfyUI-Easy-Use.git\",\n    \"comfyui-mixlab-nodes\": \"https://github.com/MixLabPro/comfyui-mixlab-nodes.git\"\n}\n\nfor plugin_name, plugin_url in all_plugins.items():\n    print(f\"\\n{'='*60}\")\n    print(f\"Â§ÑÁêÜ: {plugin_name}\")\n    print(f\"{'='*60}\")\n    \n    if not os.path.exists(plugin_name):\n        print(f\"  ‚Üí ÂÖãÈöÜ {plugin_name}...\")\n        !git clone {plugin_url}\n        \n        # Install requirements\n        req_file = f\"{plugin_name}/requirements.txt\"\n        if os.path.exists(req_file):\n            print(f\"  ‚Üí ÂÆâË£Ö‰æùËµñ...\")\n            !pip install -q -r {req_file}\n            \n        print(f\"  ‚úì {plugin_name} ÂÆåÊàê\")\n    # else:\n    #     print(f\"  ‚Üí {plugin_name} Â∑≤Â≠òÂú®ÔºåÊõ¥Êñ∞‰∏≠...\")\n    #     %cd {plugin_name}\n    #     !git pull -q\n        \n    #     # Update requirements\n    #     if os.path.exists(\"requirements.txt\"):\n    #         !pip install -q -r requirements.txt\n    #     %cd ..\n    #     print(f\"  ‚úì {plugin_name} Êõ¥Êñ∞ÂÆåÊàê\")\n\n%cd ..\nprint(\"\\n\" + \"=\"*60)\nprint(f\"‚úì ÊâÄÊúâÊèí‰ª∂ÂÆâË£ÖÂÆåÊàêÔºÅ\")\nprint(f\"ÂΩìÂâçÂ∑•‰ΩúÁõÆÂΩï: {os.getcwd()}\")\nprint(\"=\"*60)\n\n# --------------------------\n# 6.5 ÈÖçÁΩÆ ComfyUI Â§öGPUÊîØÊåÅ\n# --------------------------\nprint(\"\\n\" + \"=\"*60)\nprint(\"ÈÖçÁΩÆ ComfyUI Â§öGPUÊîØÊåÅ...\")\nprint(\"=\"*60)\n\n# Remove or fix the extra_model_paths.yaml file to prevent startup errors\nconfig_file = \"extra_model_paths.yaml\"\nif os.path.exists(config_file):\n    os.remove(config_file)\n    print(f\"‚úì Â∑≤Âà†Èô§ÊóßÈÖçÁΩÆÊñá‰ª∂: {config_file}\")\n\n# ComfyUI will use default paths, which works better with multi-GPU\nprint(\"‚úì ‰ΩøÁî®ÈªòËÆ§ÈÖçÁΩÆ (Ëá™Âä®Â§öGPUÊîØÊåÅ)\")\nprint(\"=\"*60)\n\n# Suppress warnings in environment\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONWARNINGS'] = 'ignore::FutureWarning'\n\n# Change to ComfyUI directory\n%cd /kaggle/working/ComfyUI\n\nprint(\"\\nüöÄ ÂêØÂä® ComfyUI ÊúçÂä°Âô® (Â§öGPUÊ®°Âºè)...\")\n\n# Check GPU count one more time\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    if num_gpus > 1:\n        print(f\"‚úì ÂêØÁî® {num_gpus} GPU Ê®°Âºè\")\n        print(f\"  CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'all')}\")\n    print()\nexcept:\n    pass\n\n# --------------------------\n# 7. ÂêØÂä® ComfyUI ‰Ωú‰∏∫ÂêéÂè∞ËøõÁ®ã\n# --------------------------\nimport subprocess\nimport time\nimport requests\nimport sys\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üöÄ ÂêØÂä® ComfyUI ÊúçÂä°Âô® (ÂêéÂè∞ËøõÁ®ãÊ®°Âºè)...\")\nprint(\"=\"*60)\n\n# Ensure we're in the ComfyUI directory\nos.chdir('/kaggle/working/ComfyUI')\nprint(f\"ÂΩìÂâçÁõÆÂΩï: {os.getcwd()}\")\n\n# Configure launch arguments\ncomfy_args = [\n    sys.executable,  # Use current Python interpreter\n    'main.py',\n    '--listen', '0.0.0.0',\n    '--port', '8188',\n    '--preview-method', 'auto',\n    '--cache-none',\n    '--output-directory', '/kaggle/working/ComfyUI/output'  # Add output path\n]\n\n# Add multi-GPU support if available\ntry:\n    import torch\n    num_gpus = torch.cuda.device_count()\n    if num_gpus > 1:\n        print(f\"‚úì ÈÖçÁΩÆÂ§öGPUÊ®°Âºè ({num_gpus} GPUs)\")\n        # ComfyUI will automatically use all available GPUs\nexcept:\n    pass\n\n# Start ComfyUI as background subprocess\nprint(f\"\\nÂêØÂä®ÂëΩ‰ª§: {' '.join(comfy_args)}\")\nprint(\"=\"*60)\n\ncomfy_process = subprocess.Popen(\n    comfy_args,\n    stdout=subprocess.PIPE,\n    stderr=subprocess.PIPE,\n    cwd='/kaggle/working/ComfyUI',\n    bufsize=1,\n    universal_newlines=True\n)\n\nprint(f\"‚úì ComfyUI ËøõÁ®ãÂ∑≤ÂêØÂä®\")\nprint(f\"  PID: {comfy_process.pid}\")\nprint(f\"  Áä∂ÊÄÅ: {'ËøêË°å‰∏≠' if comfy_process.poll() is None else 'Â∑≤ÂÅúÊ≠¢'}\")\n\n# --------------------------\n# 8. Á≠âÂæÖ ComfyUI Â∞±Áª™\n# --------------------------\ndef wait_for_comfyui(max_attempts=60, delay=2):\n    \"\"\"Á≠âÂæÖ ComfyUI ÊúçÂä°Âô®Â∞±Áª™\"\"\"\n    print(f\"\\n‚è≥ Á≠âÂæÖ ComfyUI ÂêØÂä® (ÊúÄÂ§ö {max_attempts * delay} Áßí)...\")\n    print(\"-\" * 60)\n    \n    for i in range(max_attempts):\n        # Check if process is still running\n        if comfy_process.poll() is not None:\n            print(f\"\\n‚úó ComfyUI ËøõÁ®ãÊÑèÂ§ñÁªàÊ≠¢!\")\n            print(\"\\nÊúÄÂêéÁöÑËæìÂá∫:\")\n            if comfy_process.stdout:\n                print(comfy_process.stdout.read())\n            if comfy_process.stderr:\n                print(\"\\nÈîôËØØËæìÂá∫:\")\n                print(comfy_process.stderr.read())\n            return False\n        \n        try:\n            # Try to connect to ComfyUI API\n            response = requests.get(\n                \"http://127.0.0.1:8188/system_stats\",\n                timeout=2\n            )\n            \n            if response.status_code == 200:\n                print(f\"\\n‚úì ComfyUI Â∑≤Â∞±Áª™! (ËÄóÊó∂ {(i+1) * delay} Áßí)\")\n                print(\"-\" * 60)\n                \n                # Print system stats\n                try:\n                    stats = response.json()\n                    print(\"\\nÁ≥ªÁªüÁä∂ÊÄÅ:\")\n                    if 'system' in stats:\n                        sys_info = stats['system']\n                        print(f\"  ‚Ä¢ OS: {sys_info.get('os', 'N/A')}\")\n                        print(f\"  ‚Ä¢ Python: {sys_info.get('python_version', 'N/A')}\")\n                    \n                    if 'devices' in stats:\n                        devices = stats['devices']\n                        print(f\"\\n  ‚Ä¢ GPU ËÆæÂ§á:\")\n                        for i, device in enumerate(devices):\n                            print(f\"    - GPU {i}: {device.get('name', 'N/A')}\")\n                            vram_total = device.get('vram_total', 0) / (1024**3)\n                            print(f\"      VRAM: {vram_total:.2f} GB\")\n                except:\n                    pass\n                \n                print(\"=\"*60)\n                return True\n                \n        except requests.exceptions.RequestException:\n            pass\n        except Exception as e:\n            pass\n        \n        # Progress indicator\n        time.sleep(delay)\n        if (i + 1) % 5 == 0:\n            print(f\"  Â∞ùËØï {i+1}/{max_attempts} - ‰ªçÂú®ÂêØÂä®‰∏≠...\")\n    \n    print(f\"\\n‚ö†Ô∏è Ë∂ÖÊó∂: ComfyUI Êú™ËÉΩÂú® {max_attempts * delay} ÁßíÂÜÖÂêØÂä®\")\n    print(\"\\nÊ£ÄÊü•ËøõÁ®ãÁä∂ÊÄÅ...\")\n    print(f\"  ËøõÁ®ãÁä∂ÊÄÅ: {'ËøêË°å‰∏≠' if comfy_process.poll() is None else 'Â∑≤ÂÅúÊ≠¢'}\")\n    \n    return False\n\n# Wait for ComfyUI to be ready\nif wait_for_comfyui():\n    print(\"\\nüéâ ComfyUI ÊúçÂä°Âô®ËøêË°åÊ≠£Â∏∏!\")\n    print(f\"    ‚Üí Êú¨Âú∞ËÆøÈóÆ: http://127.0.0.1:8188\")\n    print(f\"    ‚Üí ËøõÁ®ã PID: {comfy_process.pid}\")\n    print(\"\\n‚úì ÂèØ‰ª•ÁªßÁª≠ËøêË°å‰∏ã‰∏Ä‰∏™ÂçïÂÖÉÊ†ºÂêØÂä® Gradio\")\nelse:\n    print(\"\\n‚ö†Ô∏è  ComfyUI ÂêØÂä®ÂèØËÉΩÈÅáÂà∞ÈóÆÈ¢ò\")\n    print(\"    ‚Üí Âª∫ËÆÆÊ£ÄÊü•‰∏ãÈù¢ÁöÑÊó•ÂøóËæìÂá∫\")\n    print(\"    ‚Üí ÊàñËøêË°åË∞ÉËØïÂçïÂÖÉÊ†ºÊü•ÁúãËØ¶ÁªÜÈîôËØØ\")\n\nprint(\"=\"*60)\n\n# --------------------------\n# 9. ÂèØÈÄâ: ÂÆûÊó∂Êü•Áúã ComfyUI Êó•Âøó\n# --------------------------\n# Â¶ÇÊûúÈúÄË¶ÅÊü•ÁúãÂÆûÊó∂Êó•ÂøóÔºåÂèØ‰ª•ËøêË°åËøô‰∏™ÂçïÂÖÉÊ†º:\n\nimport threading\n\ndef stream_output(pipe, label):\n    '''ÂÆûÊó∂ÊâìÂç∞ËøõÁ®ãËæìÂá∫'''\n    for line in iter(pipe.readline, ''):\n        if line:\n            print(f\"[{label}] {line.rstrip()}\")\n\n# ÂàõÂª∫Êó•ÂøóÁ∫øÁ®ã\nstdout_thread = threading.Thread(\n    target=stream_output, \n    args=(comfy_process.stdout, \"STDOUT\"),\n    daemon=True\n)\nstderr_thread = threading.Thread(\n    target=stream_output,\n    args=(comfy_process.stderr, \"STDERR\"),\n    daemon=True\n)\n\nstdout_thread.start()\nstderr_thread.start()\n\nprint(\"‚úì Êó•ÂøóÁõëÊéßÂ∑≤ÂêØÂä® (ÂêéÂè∞ËøêË°å)\")\n\n# --------------------------\n# 10. Ë∞ÉËØïÂçïÂÖÉÊ†º (ÂèØÈÄâ)\n# --------------------------\n# Â¶ÇÊûú ComfyUI ÂêØÂä®Â§±Ë¥•ÔºåËøêË°åËøô‰∏™Êù•Êü•ÁúãËØ¶ÁªÜ‰ø°ÊÅØ:\n\nprint(\"=\"*60)\nprint(\"ComfyUI ËøõÁ®ãËØäÊñ≠\")\nprint(\"=\"*60)\n\nprint(f\"\\nËøõÁ®ã PID: {comfy_process.pid}\")\nprint(f\"ËøõÁ®ãÁä∂ÊÄÅ: {comfy_process.poll()}\")\nprint(f\"ËøêË°å‰∏≠: {comfy_process.poll() is None}\")\n\nif comfy_process.poll() is not None:\n    print(\"\\n‚ö†Ô∏è  ËøõÁ®ãÂ∑≤ÂÅúÊ≠¢\")\n    \n    print(\"\\nÊ†áÂáÜËæìÂá∫:\")\n    print(\"-\" * 60)\n    if comfy_process.stdout:\n        stdout = comfy_process.stdout.read()\n        print(stdout if stdout else \"(Êó†ËæìÂá∫)\")\n    \n    print(\"\\nÊ†áÂáÜÈîôËØØ:\")\n    print(\"-\" * 60)\n    if comfy_process.stderr:\n        stderr = comfy_process.stderr.read()\n        print(stderr if stderr else \"(Êó†ÈîôËØØ)\")\nelse:\n    print(\"\\n‚úì ËøõÁ®ã‰ªçÂú®ËøêË°å\")\n    \n    # Test API connection\n    try:\n        response = requests.get(\"http://127.0.0.1:8188/system_stats\", timeout=2)\n        print(f\"\\n‚úì API ÂìçÂ∫î: {response.status_code}\")\n        print(response.json())\n    except Exception as e:\n        print(f\"\\n‚úó API ËøûÊé•Â§±Ë¥•: {e}\")\n\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:41:58.540155Z","iopub.execute_input":"2025-11-19T17:41:58.540425Z","iopub.status.idle":"2025-11-19T17:54:05.544313Z","shell.execute_reply.started":"2025-11-19T17:41:58.540403Z","shell.execute_reply":"2025-11-19T17:54:05.543283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GRADIO + COMFYUI API (In case if Localtunnel connection is unstable)\n\n!pip install gradio requests websocket-client pillow\n\nimport json\nimport requests\nimport gradio as gr\nimport websocket\nimport uuid\nimport urllib.request\nimport urllib.parse\nfrom PIL import Image\nimport io\nimport os\nimport time\n\nclass ComfyUIAPI:\n    def __init__(self, server_address=\"127.0.0.1:8188\"):\n        self.server_address = server_address\n        self.client_id = str(uuid.uuid4())\n        \n    def queue_prompt(self, prompt):\n        \"\"\"Queue a prompt to ComfyUI\"\"\"\n        p = {\"prompt\": prompt, \"client_id\": self.client_id}\n        data = json.dumps(p).encode('utf-8')\n        req = urllib.request.Request(f\"http://{self.server_address}/prompt\", data=data)\n        return json.loads(urllib.request.urlopen(req).read())\n    \n    def upload_image(self, image_path, subfolder=\"\", overwrite=False):\n        \"\"\"Upload an image to ComfyUI\"\"\"\n        with open(image_path, 'rb') as f:\n            files = {'image': f}\n            data = {\n                'subfolder': subfolder,\n                'overwrite': str(overwrite).lower()\n            }\n            response = requests.post(\n                f\"http://{self.server_address}/upload/image\",\n                files=files,\n                data=data\n            )\n        return response.json()\n    \n    def upload_video(self, video_path, subfolder=\"\", overwrite=True):\n        \"\"\"Upload a video to ComfyUI\"\"\"\n        with open(video_path, 'rb') as f:\n            files = {'image': (os.path.basename(video_path), f, 'video/mp4')}\n            data = {\n                'subfolder': subfolder,\n                'overwrite': str(overwrite).lower(),\n                'type': 'input'\n            }\n            response = requests.post(\n                f\"http://{self.server_address}/upload/image\",\n                files=files,\n                data=data\n            )\n        return response.json()\n    \n    def get_history(self, prompt_id):\n        \"\"\"Get the execution history for a prompt\"\"\"\n        req = urllib.request.Request(f\"http://{self.server_address}/history/{prompt_id}\")\n        return json.loads(urllib.request.urlopen(req).read())\n    \n    def get_image(self, filename, subfolder, folder_type):\n        \"\"\"Download an image from ComfyUI\"\"\"\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        url = f\"http://{self.server_address}/view?{url_values}\"\n        with urllib.request.urlopen(url) as response:\n            return response.read()\n    \n    def get_video(self, filename, subfolder, folder_type, save_path):\n        \"\"\"Download a video from ComfyUI and save it locally\"\"\"\n        data = {\"filename\": filename, \"subfolder\": subfolder, \"type\": folder_type}\n        url_values = urllib.parse.urlencode(data)\n        url = f\"http://{self.server_address}/view?{url_values}\"\n        \n        # Download video\n        with urllib.request.urlopen(url) as response:\n            video_data = response.read()\n        \n        # Save to file\n        with open(save_path, 'wb') as f:\n            f.write(video_data)\n        \n        return save_path\n    \n    def track_progress(self, prompt_id, progress_callback=None):\n        \"\"\"Track workflow execution progress via WebSocket\"\"\"\n        ws = websocket.WebSocket()\n        ws.connect(f\"ws://{self.server_address}/ws?clientId={self.client_id}\")\n        \n        while True:\n            out = ws.recv()\n            if isinstance(out, str):\n                message = json.loads(out)\n                \n                if message['type'] == 'progress' and progress_callback:\n                    data = message['data']\n                    progress_callback(data.get('value', 0), data.get('max', 100))\n                \n                if message['type'] == 'executing':\n                    data = message['data']\n                    if data['node'] is None and data['prompt_id'] == prompt_id:\n                        break\n        ws.close()\n\nclass WanVideoGradioApp:\n    def __init__(self):\n        self.api = ComfyUIAPI()\n        self.workflow = None\n        self.temp_dir = \"gradio_outputs\"\n        os.makedirs(self.temp_dir, exist_ok=True)\n        \n    def load_workflow(self, workflow_file):\n        \"\"\"Load the WanVideo workflow JSON file\"\"\"\n        try:\n            if workflow_file is None:\n                return \"‚ö† Please upload a workflow file\"\n                \n            with open(workflow_file.name, 'r') as f:\n                self.workflow = json.load(f)\n            return f\"‚úì Workflow loaded successfully! Found {len(self.workflow)} nodes.\\nReady to process videos.\"\n        except Exception as e:\n            return f\"‚úó Error loading workflow: {str(e)}\"\n    \n    def run_workflow(self, prompt_text, negative_prompt, input_image, input_video, \n                    length_seconds, framerate, resolution, interpolation_factor, seed):\n        \"\"\"Execute the WanVideo workflow with provided inputs\"\"\"\n        if not self.workflow:\n            return \"‚ö† Please load a workflow first!\", None, None, None\n        \n        try:\n            status_updates = []\n            \n            # Upload image\n            if input_image:\n                status_updates.append(\"üì§ Uploading image...\")\n                img_result = self.api.upload_image(input_image)\n                self.workflow[\"64\"][\"inputs\"][\"image\"] = img_result['name']\n                status_updates.append(f\"‚úì Image uploaded: {img_result['name']}\")\n            \n            # Upload video\n            if input_video:\n                status_updates.append(\"üì§ Uploading video...\")\n                vid_result = self.api.upload_video(input_video)\n                self.workflow[\"13\"][\"inputs\"][\"video\"] = vid_result['name']\n                status_updates.append(f\"‚úì Video uploaded: {vid_result['name']}\")\n            \n            # Update text prompts\n            if prompt_text:\n                self.workflow[\"124\"][\"inputs\"][\"text\"] = prompt_text\n            if negative_prompt:\n                self.workflow[\"122\"][\"inputs\"][\"text\"] = negative_prompt\n            \n            # Update parameters\n            self.workflow[\"28\"][\"inputs\"][\"value\"] = float(length_seconds)\n            self.workflow[\"30\"][\"inputs\"][\"value\"] = float(framerate)\n            self.workflow[\"32\"][\"inputs\"][\"value\"] = int(resolution)\n            self.workflow[\"29\"][\"inputs\"][\"value\"] = int(interpolation_factor)\n            self.workflow[\"90\"][\"inputs\"][\"seed\"] = int(seed)\n            \n            status_updates.append(\"‚öôÔ∏è Starting workflow execution...\")\n            \n            # Queue the prompt\n            result = self.api.queue_prompt(self.workflow)\n            prompt_id = result['prompt_id']\n            status_updates.append(f\"‚úì Workflow queued (ID: {prompt_id[:8]}...)\")\n            \n            # Track progress\n            status_updates.append(\"üîÑ Processing... This may take several minutes.\")\n            self.api.track_progress(prompt_id)\n            \n            status_updates.append(\"‚úì Workflow completed!\")\n            status_updates.append(\"üì¶ Retrieving outputs...\")\n            \n            # Get output\n            time.sleep(2)  # Wait for files to be written\n            history = self.api.get_history(prompt_id)[prompt_id]\n            \n            # Get output images/videos\n            output_images = []\n            output_videos = []\n            output_info = []\n            \n            for node_id in history['outputs']:\n                node_output = history['outputs'][node_id]\n                \n                # Get images\n                if 'images' in node_output:\n                    for image in node_output['images']:\n                        try:\n                            image_data = self.api.get_image(\n                                image['filename'], \n                                image['subfolder'], \n                                image['type']\n                            )\n                            img = Image.open(io.BytesIO(image_data))\n                            output_images.append(img)\n                            output_info.append(f\"Image: {image['filename']}\")\n                        except Exception as e:\n                            status_updates.append(f\"‚ö† Could not load image: {str(e)}\")\n                \n                # Get videos (including gifs)\n                if 'gifs' in node_output:\n                    for idx, video in enumerate(node_output['gifs']):\n                        try:\n                            # Save video locally\n                            video_filename = f\"output_{prompt_id[:8]}_{idx}.mp4\"\n                            video_path = os.path.join(self.temp_dir, video_filename)\n                            \n                            self.api.get_video(\n                                video['filename'],\n                                video['subfolder'],\n                                video['type'],\n                                video_path\n                            )\n                            \n                            output_videos.append(video_path)\n                            output_info.append(f\"Video: {video['filename']} ‚Üí {video_filename}\")\n                            status_updates.append(f\"‚úì Downloaded: {video['filename']}\")\n                        except Exception as e:\n                            status_updates.append(f\"‚ö† Could not download video: {str(e)}\")\n            \n            status_updates.append(f\"‚úì Found {len(output_info)} outputs\")\n            \n            final_status = \"\\n\".join(status_updates)\n            \n            # Return outputs\n            preview_image = output_images[0] if output_images else None\n            base_video = output_videos[0] if len(output_videos) > 0 else None\n            interpolated_video = output_videos[1] if len(output_videos) > 1 else None\n            \n            return final_status, preview_image, base_video, interpolated_video\n                \n        except Exception as e:\n            error_msg = f\"‚úó Error executing workflow: {str(e)}\"\n            import traceback\n            error_msg += f\"\\n\\nDetails:\\n{traceback.format_exc()}\"\n            return error_msg, None, None, None\n\n# Initialize the app\napp = WanVideoGradioApp()\n\n# Create Gradio interface\nwith gr.Blocks(title=\"WanVideo ComfyUI Controller\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"\"\"\n    # üé¨ WanVideo Animation Controller\n    ### Control WanVideo workflow via ComfyUI API with Gradio\n    \"\"\")\n    \n    with gr.Row():\n        workflow_file = gr.File(\n            label=\"üìÅ Upload Workflow JSON (wan_2_2_animate.json)\",\n            file_types=[\".json\"]\n        )\n        load_btn = gr.Button(\"Load Workflow\", variant=\"primary\", size=\"sm\")\n    \n    workflow_status = gr.Textbox(\n        label=\"Workflow Status\",\n        interactive=False,\n        lines=2\n    )\n    \n    gr.Markdown(\"---\")\n    gr.Markdown(\"### üé® Input Configuration\")\n    \n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"**üìù Text Inputs**\")\n            prompt_text = gr.Textbox(\n                label=\"Positive Prompt\",\n                placeholder=\"Describe the animation you want...\",\n                lines=3,\n                value=\"Shrek is dancing.\"\n            )\n            negative_prompt = gr.Textbox(\n                label=\"Negative Prompt\",\n                placeholder=\"What to avoid in the animation...\",\n                lines=3,\n                value=\"overexposed, static, blurry details, low quality\"\n            )\n        \n        with gr.Column():\n            gr.Markdown(\"**üñºÔ∏è Media Inputs**\")\n            input_image = gr.Image(\n                label=\"Reference Image\",\n                type=\"filepath\",\n                height=200\n            )\n            input_video = gr.Video(\n                label=\"Input Video (Optional)\",\n                height=200\n            )\n    \n    gr.Markdown(\"### ‚öôÔ∏è Generation Parameters\")\n    \n    with gr.Row():\n        length_seconds = gr.Slider(\n            minimum=1,\n            maximum=30,\n            value=7,\n            step=1,\n            label=\"üé¨ Length (Seconds)\"\n        )\n        framerate = gr.Slider(\n            minimum=8,\n            maximum=60,\n            value=16,\n            step=1,\n            label=\"üé¶ Framerate (FPS)\"\n        )\n    \n    with gr.Row():\n        resolution = gr.Slider(\n            minimum=256,\n            maximum=1024,\n            value=480,\n            step=64,\n            label=\"üî≤ Resolution (Width)\"\n        )\n        interpolation_factor = gr.Slider(\n            minimum=1,\n            maximum=4,\n            value=2,\n            step=1,\n            label=\"üîÄ Interpolation Factor\"\n        )\n    \n    seed = gr.Number(\n        label=\"üé≤ Seed\",\n        value=777,\n        precision=0\n    )\n    \n    run_btn = gr.Button(\"‚ñ∂ Generate Animation\", variant=\"primary\", size=\"lg\")\n    \n    gr.Markdown(\"---\")\n    gr.Markdown(\"### üìä Results\")\n    \n    execution_status = gr.Textbox(\n        label=\"Execution Log\",\n        interactive=False,\n        lines=8\n    )\n    \n    with gr.Row():\n        with gr.Column():\n            output_image = gr.Image(\n                label=\"Preview Frame\"\n            )\n        with gr.Column():\n            base_video_output = gr.Video(\n                label=\"Base Animation\"\n            )\n    \n    interpolated_video_output = gr.Video(\n        label=\"Interpolated Animation (High FPS)\"\n    )\n    \n    gr.Markdown(\"\"\"\n    ---\n    ### üìñ Instructions:\n    \n    1. **Load Workflow**: Upload the `wan_2_2_animate.json` file\n    2. **Set Prompts**: Describe the animation you want to create\n    3. **Upload Media**: \n       - **Required**: Reference image (character/subject)\n       - **Optional**: Input video for motion reference\n    4. **Adjust Parameters**: \n       - Length: Duration in seconds\n       - Framerate: Higher = smoother but slower to generate\n       - Resolution: Output width (height auto-calculated)\n       - Interpolation: Multiplier for frame interpolation (2 = double frames)\n    5. **Generate**: Click \"Generate Animation\" and wait\n    \n    **Outputs**: \n    - Base Animation: Original generated video at specified FPS\n    - Interpolated Animation: Enhanced version with interpolated frames for smoother motion\n    \n    **Note**: Make sure ComfyUI is running on `127.0.0.1:8188` with all required models loaded.\n    \"\"\")\n    \n    # Event handlers\n    load_btn.click(\n        fn=app.load_workflow,\n        inputs=[workflow_file],\n        outputs=[workflow_status]\n    )\n    \n    run_btn.click(\n        fn=app.run_workflow,\n        inputs=[\n            prompt_text,\n            negative_prompt,\n            input_image,\n            input_video,\n            length_seconds,\n            framerate,\n            resolution,\n            interpolation_factor,\n            seed\n        ],\n        outputs=[execution_status, output_image, base_video_output, interpolated_video_output]\n    )\n    \n    # Load example\n    gr.Examples(\n        examples=[\n            [\"A person dancing energetically\", \"static, blurry, low quality\", 5, 16, 480, 2, 777],\n            [\"Character walking forward confidently\", \"overexposed, static, ugly\", 7, 16, 512, 2, 123],\n        ],\n        inputs=[prompt_text, negative_prompt, length_seconds, framerate, resolution, interpolation_factor, seed],\n    )\n\n\n# demo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:58:29.201105Z","iopub.execute_input":"2025-11-19T17:58:29.202448Z","iopub.status.idle":"2025-11-19T17:58:40.988979Z","shell.execute_reply.started":"2025-11-19T17:58:29.202398Z","shell.execute_reply":"2025-11-19T17:58:40.988172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ndemo.launch(share=True, prevent_thread_lock=True)\n\nprint(\"Keeping notebook alive...\")\nprint(\"Public URL will be shown above\")\n\n# Keep the notebook running indefinitely\nwhile True:\n    time.sleep(60)\n    print(\".\", end=\"\", flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T17:58:29.201105Z","iopub.execute_input":"2025-11-19T17:58:29.202448Z","iopub.status.idle":"2025-11-19T17:58:40.988979Z","shell.execute_reply.started":"2025-11-19T17:58:29.202398Z","shell.execute_reply":"2025-11-19T17:58:40.988172Z"}},"outputs":[],"execution_count":null}]}